{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "93c552aa-0827-450f-b80f-bb58ddccf126",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "import re, os, glob\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d884d8c5-ba49-43f7-9f7c-1d1835850cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "WORDS_ONLY = re.compile(r\"[a-z]+\") # storing only words cuz it's more convenient to analyze with words only\n",
    "\n",
    "def load_text(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return f.read().replace(\"\\r\\n\",\"\\n\").replace(\"\\r\",\"\\n\") # replace \\r\\n with \\n and then replace \\r with \\n\n",
    "\n",
    "#def load_docs(pattern=\"../data/*.txt\"): # all of my files end w .txt in data\n",
    "    #return {Path(p).stem: load_text(p) for p in glob.glob(pattern)}\n",
    "\n",
    "docs = {Path(p).stem: load_text(p) for p in glob.glob(\"../data/*.txt\")}\n",
    "tokens = {name: words_only(txt) for name, txt in docs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cd1a488e-cf84-440f-a9e5-91b2f1a6726f",
   "metadata": {},
   "outputs": [],
   "source": [
    "START = re.compile(r\"\\*\\*\\*\\s*START OF (?:THE|THIS) PROJECT GUTENBERG EBOOK.*?\\*\\*\\*\", re.I|re.S) # strip header\n",
    "END   = re.compile(r\"\\*\\*\\*\\s*END OF (?:THE|THIS) PROJECT GUTENBERG EBOOK.*\", re.I|re.S) # strip footer\n",
    "\n",
    "# ivxlcdm is normal AND roman numbers\n",
    "RAW_CONTENT = re.compile(r\"^(?:preface|chapter\\s+(?:\\d+|[ivxlcdm]+))\\b\", flags=re.I | re.M) \n",
    "\n",
    "# most books start with preface or chapter x\n",
    "HEAD_START = re.compile(r\"^\\s*(chapter\\b|contents\\b|epilogue\\b|preface\\b|prologue\\b|etymology\\b)\", re.I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4ea43cb2-41b0-4f39-b267-f08c99dd7d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_content(text): # strip the gutenberg start and end points\n",
    "    text = text.replace(\"\\r\\n\",\"\\n\").replace(\"\\r\",\"\\n\")\n",
    "    detect = START.search(text)\n",
    "    if detect: \n",
    "        text = text[detect.end():]\n",
    "    detect = END.search(text)\n",
    "    if detect: \n",
    "        text = text[:detect.start()]\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e5d22a8b-c7ff-4110-8143-b4f630086a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def starting_point(text): # start at preface or chapter sth sth line\n",
    "    detect = RAW_CONTENT.search(text)\n",
    "    if detect:\n",
    "        lineStart = text.rfind(\"\\n\", 0, detect.start()) + 1 # teleport to the start of the line\n",
    "        return text[lineStart:].lstrip() # if cant find the keyword preface or chapter, return to the original\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f5fc2670-6b19-48ea-8cd4-73f0e2280ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def additional_removals(text):\n",
    "    keptWords = []\n",
    "    for line in text.splitlines():\n",
    "        if HEAD_START.match(line.strip()):\n",
    "            continue\n",
    "        keptWords.append(line)\n",
    "    return re.sub(r\"\\n{3,}\", \"\\n\\n\", \"\\n\".join(keptWords)).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c7baf9bb-fb39-4331-aa26-b866801d1325",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_transcriber(text):\n",
    "    bigNO = (\"transcriber\", \"transcriber's note\", \"proofreading\", \"pgdp\", \"proofreaders\", \"illustration\", \"copyright\", \"'\", \"ll\", \"mr\", \"mrs\", \"dr\")\n",
    "    return \"\\n\".join(line for line in text.splitlines()\n",
    "                     if not any(b in line.lower() for b in bigNO))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "29f42dfc-18e0-4e75-a780-c7ad6bf90cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUZZWORDS = {\"chapter\",\"chap\",\"book\",\"preface\",\"contents\",\"page\",\n",
    "             \"project\",\"gutenberg\",\"ebook\",\"transcriber\",\"pgdp\", \"illustration\", \"copyright\", \"'\", \"ll\", \"mr\", \"mrs\", \"dr\"}\n",
    "def tokenize(text): # basic tokenization of the body explained in the handout\n",
    "    toks = WORDS_ONLY.findall(text.lower())\n",
    "    return [t for t in toks if t not in BUZZWORDS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fef405b5-b04f-4727-8c3b-f553dc8a4b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning data\n",
    "def clean(unclean):\n",
    "    content = strip_content(unclean)\n",
    "    content = starting_point(content)  # drop everything before preface OR chapter cuz we dont want them\n",
    "    content = additional_removals(content)\n",
    "    content = remove_transcriber(content)\n",
    "    toks = tokenize(content)\n",
    "    return content, toks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "daf29876-9f7f-4148-932f-15c4780865b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorting words for each book w dictionary\n",
    "pattern = \"../data/*.txt\"\n",
    "tokens_per_book = {}\n",
    "content_per_book = {}\n",
    "\n",
    "for p in glob.glob(pattern):\n",
    "    name = Path(p).stem\n",
    "    unclean = load_text(p)\n",
    "    content, toks = clean(unclean)\n",
    "    content_per_book = content\n",
    "    tokens_per_book[name] = toks\n",
    "\n",
    "book_names  = sorted(tokens_per_book.keys())\n",
    "token_lists = [tokens_per_book[n] for n in book_names]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
